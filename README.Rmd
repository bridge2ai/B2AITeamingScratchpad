---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# B2AITeamingScratchpad

<!-- badges: start -->
<!-- badges: end -->

## Installation

You can install the development version of B2AITeamingScratchpad like so:

```{r eval=FALSE}
library(remotes)
remotes::install_github('seandavi/B2AITeamingScratchpad')
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example}
library(B2AITeamingScratchpad)
```

### Fetch all publications by orcid

```{r}
orcid_example = '0000-0002-8991-6458'
works_df = works_from_orcid(orcid_example)
```

The result is a data.frame with some minimal information about each publication.

```{r}
colnames(works_df)
dim(works_df)
head(works_df)
```

### Fetch details about one of the publications

```{r}
work_details = orcid_work_detail(orcid_example, works_df$put_code[6])
dplyr::glimpse(work_details)
```

## Bridge2AI Expertise analysis

See the [vignettes directory](vignettes).

## The Bridge2AI Program

The NIH Common Fund’s Bridge to Artificial Intelligence (Bridge2AI) program will propel biomedical research forward by setting the stage for widespread adoption of artificial intelligence (AI) that tackles complex biomedical challenges beyond human intuition. A key step in this process is generating new “flagship” data sets and best practices for machine learning analysis. Machine learning is a type of Artificial Intelligence (AI) that provides machines (like computers) the ability to automatically learn and improve from experience, without being explicitly programmed. The biomedical research community generates a wealth of data, but most of these data are not suitable for machine learning because they are incomplete. By bringing technological and biomedical experts together with social scientists and humanists, the Bridge2AI program will help bring solutions to this deficit by:

* Generating new flagship biomedical and behavioral data sets that are ethically sourced, trustworthy, well-defined, and accessible
* Developing software and standards to unify data attributes across multiple data sources and across data types
* Creating automated tools to accelerate the creation of FAIR (Findable, Accessible, Interoperable, and Reusable) and ethically sourced data sets
* Providing resources to disseminate data, ethical principles, tools, and best practices
* Creating training materials and activities for workforce development that bridges the AI, biomedical, and behavioral research communities
